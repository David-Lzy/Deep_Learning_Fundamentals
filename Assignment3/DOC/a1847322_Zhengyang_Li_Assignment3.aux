\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{cryptocurrencyJFEC,cryptocurrencyCybersecurity}
\citation{Szegedy15}
\@LN@col{1}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.\nobreakspace  {}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{brf}{\backcite{cryptocurrencyCybersecurity}{{1}{1}{section.1}}}
\@writefile{brf}{\backcite{cryptocurrencyJFEC}{{1}{1}{section.1}}}
\@LN@col{2}
\@writefile{brf}{\backcite{Szegedy15}{{1}{1}{section.1}}}
\citation{Szegedy15}
\citation{FuzzyInferenceLSTM}
\@LN@col{1}
\@writefile{brf}{\backcite{Szegedy15}{{2}{1}{section.1}}}
\@writefile{brf}{\backcite{FuzzyInferenceLSTM}{{2}{1}{section.1}}}
\@LN@col{2}
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.\nobreakspace  {}Method}{2}{section.2}\protected@file@percent }
\newlabel{sec:method}{{2}{2}{\hskip -1em.~Method}{section.2}{}}
\newlabel{sec:method@cref}{{[section][2][]2}{[1][2][]2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}\hskip -1em.\nobreakspace  {}Feature Engineering}{2}{subsection.2.1}\protected@file@percent }
\citation{PoonGranger,Psaradellis}
\citation{PoonGranger,JarenoGarcia}
\citation{PoonGranger}
\citation{TongChio}
\@LN@col{1}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Relative Strength Index (RSI)}{3}{subsubsection.2.1.1}\protected@file@percent }
\@writefile{brf}{\backcite{PoonGranger}{{3}{2.1.1}{subsubsection.2.1.1}}}
\@writefile{brf}{\backcite{Psaradellis}{{3}{2.1.1}{subsubsection.2.1.1}}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Bollinger Bands}{3}{subsubsection.2.1.2}\protected@file@percent }
\@writefile{brf}{\backcite{JarenoGarcia}{{3}{2.1.2}{subsubsection.2.1.2}}}
\@writefile{brf}{\backcite{PoonGranger}{{3}{2.1.2}{subsubsection.2.1.2}}}
\@LN@col{2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Moving Averages}{3}{subsubsection.2.1.3}\protected@file@percent }
\@writefile{brf}{\backcite{PoonGranger}{{3}{2.1.3}{subsubsection.2.1.3}}}
\citation{RumelhartHintonWilliams}
\@LN@col{1}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4}Moving Average Convergence Divergence}{4}{subsubsection.2.1.4}\protected@file@percent }
\@writefile{brf}{\backcite{TongChio}{{4}{2.1.4}{subsubsection.2.1.4}}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.5}Average True Range (ATR)}{4}{subsubsection.2.1.5}\protected@file@percent }
\@writefile{brf}{\backcite{RumelhartHintonWilliams}{{4}{2.1.5}{subsubsection.2.1.5}}}
\@LN@col{2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.6}On-Balance Volume (OBV)}{4}{subsubsection.2.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}\hskip -1em.\nobreakspace  {}Time Series Models}{4}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Recurrent Neural Networks (RNNs)}{4}{subsubsection.2.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Plot of Architecture of a traditional RNNRecurrent neural networks, also known as RNNs, a class of neural networks that allow previous outputs to be used as inputs while having hidden states.\relax }}{4}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig1}{{1}{4}{Plot of Architecture of a traditional RNNRecurrent neural networks, also known as RNNs, a class of neural networks that allow previous outputs to be used as inputs while having hidden states.\relax }{figure.caption.1}{}}
\newlabel{fig1@cref}{{[figure][1][]1}{[1][4][]4}}
\citation{HochreiterSchmidhuber}
\citation{FuzzyInferenceLSTM}
\citation{FuzzyInferenceLSTM}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Recurrent Neural Network (RNN) Pseudocode\relax }}{5}{algorithm.1}\protected@file@percent }
\@LN@col{1}
\@writefile{brf}{\backcite{HochreiterSchmidhuber}{{5}{2.2.1}{figure.caption.1}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Plot of how the information in time step $t-1$ influence time step $t$ in a traditional RNN model.\relax }}{5}{figure.caption.2}\protected@file@percent }
\newlabel{fig2}{{2}{5}{Plot of how the information in time step $t-1$ influence time step $t$ in a traditional RNN model.\relax }{figure.caption.2}{}}
\newlabel{fig2@cref}{{[figure][2][]2}{[1][5][]5}}
\@LN@col{2}
\@writefile{brf}{\backcite{FuzzyInferenceLSTM}{{5}{2.2.1}{figure.caption.2}}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Long Short-Term Memory (LSTM) Networks}{5}{subsubsection.2.2.2}\protected@file@percent }
\@writefile{brf}{\backcite{FuzzyInferenceLSTM}{{5}{2.2.2}{subsubsection.2.2.2}}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Plot of a demo what the differences between RNN and lstm in handling input.\relax }}{5}{figure.caption.3}\protected@file@percent }
\newlabel{fig3}{{3}{5}{Plot of a demo what the differences between RNN and lstm in handling input.\relax }{figure.caption.3}{}}
\newlabel{fig3@cref}{{[figure][3][]3}{[1][5][]5}}
\@LN@col{1}
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.\nobreakspace  {}Experimentation}{6}{section.3}\protected@file@percent }
\newlabel{sec:experimentation}{{3}{6}{\hskip -1em.~Experimentation}{section.3}{}}
\newlabel{sec:experimentation@cref}{{[section][3][]3}{[1][6][]6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}\hskip -1em.\nobreakspace  {}Data Preprocessing}{6}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Data Acquisition}{6}{subsubsection.3.1.1}\protected@file@percent }
\@LN@col{2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Data Augmentation and Price Normalization}{6}{subsubsection.3.1.2}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Long Short-Term Memory (LSTM) Pseudocode\relax }}{7}{algorithm.2}\protected@file@percent }
\@LN@col{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}\hskip -1em.\nobreakspace  {}Experimentation Environment}{7}{subsection.3.2}\protected@file@percent }
\@LN@col{2}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}\hskip -1em.\nobreakspace  {}Experimental Parameters and Model Hyperparameter Selection}{7}{subsection.3.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Metrics of Models with Different Complexities. Note, all the results performed poorly on such a long time series (From 01/01/2017 to 31/12/2022 with time scale 1 day). This results suggest that the RNN and LSTM model are not able to learn the patterns in such a long data.\relax }}{8}{table.caption.4}\protected@file@percent }
\newlabel{tab:performance_metrics_transposed}{{1}{8}{Metrics of Models with Different Complexities. Note, all the results performed poorly on such a long time series (From 01/01/2017 to 31/12/2022 with time scale 1 day). This results suggest that the RNN and LSTM model are not able to learn the patterns in such a long data.\relax }{table.caption.4}{}}
\newlabel{tab:performance_metrics_transposed@cref}{{[table][1][]1}{[1][7][]8}}
\@LN@col{1}
\@LN@col{2}
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.\nobreakspace  {}Results}{8}{section.4}\protected@file@percent }
\newlabel{sec:results}{{4}{8}{\hskip -1em.~Results}{section.4}{}}
\newlabel{sec:results@cref}{{[section][4][]4}{[1][8][]8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}\hskip -1em.\nobreakspace  {}Challenges Posed by Extended Time-Series in Training}{8}{subsection.4.1}\protected@file@percent }
\@LN@col{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}\hskip -1em.\nobreakspace  {}Limitations of RNN and LSTM in Handling Extended Time-Series}{9}{subsection.4.2}\protected@file@percent }
\@LN@col{2}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Metrics of Models with Different dataset length. Note, the value in $dataset length$ means the number of dataset, instead the time scales of all dataset.\relax }}{9}{table.caption.5}\protected@file@percent }
\newlabel{tab:performance_metrics_transposed}{{2}{9}{Metrics of Models with Different dataset length. Note, the value in $dataset length$ means the number of dataset, instead the time scales of all dataset.\relax }{table.caption.5}{}}
\newlabel{tab:performance_metrics_transposed@cref}{{[table][2][]2}{[1][9][]9}}
\@writefile{toc}{\contentsline {section}{\numberline {5}\hskip -1em.\nobreakspace  {}Summary and Conclusion}{9}{section.5}\protected@file@percent }
\newlabel{sec:summary}{{5}{9}{\hskip -1em.~Summary and Conclusion}{section.5}{}}
\newlabel{sec:summary@cref}{{[section][5][]5}{[1][9][]9}}
\bibstyle{ieeenat_fullname}
\bibdata{main}
\bibcite{TongChio}{{1}{2022}{{Chio}}{{}}}
\bibcite{HochreiterSchmidhuber}{{2}{1997}{{Hochreiter and Schmidhuber}}{{}}}
\bibcite{JarenoGarcia}{{3}{2001}{{Jareño and García}}{{}}}
\bibcite{FuzzyInferenceLSTM}{{4}{Date not specified}{{not specified}}{{}}}
\bibcite{PoonGranger}{{5}{1997}{{Poon and Granger}}{{}}}
\bibcite{Psaradellis}{{6}{2015}{{Psaradellis et~al.}}{{}}}
\bibcite{cryptocurrencyCybersecurity}{{7}{2019}{{Rueckert}}{{}}}
\bibcite{RumelhartHintonWilliams}{{8}{1986}{{Rumelhart et~al.}}{{Rumelhart, Hinton, and Williams}}}
\bibcite{Szegedy15}{{9}{2015}{{Szegedy et~al.}}{{Szegedy, Liu, Jia, Sermanet, Reed, Anguelov, Erhan, Vanhoucke, and Rabinovich}}}
\bibcite{cryptocurrencyJFEC}{{10}{2020}{{Wolfgang Karl~Härdle}}{{}}}
\@LN@col{1}
\@LN@col{2}
\gdef \@abspage@last{10}
